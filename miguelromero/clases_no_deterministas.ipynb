{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases de datos no deterministas\n",
    "\n",
    "- variables como cualidades\n",
    "- cualidades como composición de una cualidad más primaria / natural?\n",
    "- El conocerte te marca tu destino. Tu historia muy personal es quien eres y seras cada evento es una dimensión más, un paso más, un nivel mas, un grado de composición más.\n",
    "\n",
    "- Cuáles son los factores que determinan sí el día de mañana llovera?\n",
    "- Un modelo puede determinar un zudoku\n",
    "\n",
    "- en el sudoku voy al estado más facil cada que completo \n",
    "\n",
    "\n",
    "- Algoritmo mental\n",
    "  - Hipotesis sobre el número desaparecido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inranker\n",
      "  Using cached inranker-1.1.0-py3-none-any.whl.metadata (469 bytes)\n",
      "Collecting accelerate==0.20.1 (from inranker)\n",
      "  Using cached accelerate-0.20.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting bitsandbytes==0.41.1 (from inranker)\n",
      "  Using cached bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting datasets==2.9.0 (from inranker)\n",
      "  Using cached datasets-2.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting protobuf==3.20.1 (from inranker)\n",
      "  Using cached protobuf-3.20.1-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting requests==2.31.0 (from inranker)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sentencepiece==0.1.99 (from inranker)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting torch==2.1.1 (from inranker)\n",
      "  Using cached torch-2.1.1-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting tqdm==4.66.1 (from inranker)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==4.27.4 (from inranker)\n",
      "  Using cached transformers-4.27.4-py3-none-any.whl.metadata (106 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from accelerate==0.20.1->inranker) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from accelerate==0.20.1->inranker) (23.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate==0.20.1->inranker) (5.9.8)\n",
      "Collecting pyyaml (from accelerate==0.20.1->inranker)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting pyarrow>=6.0.0 (from datasets==2.9.0->inranker)\n",
      "  Using cached pyarrow-15.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.7 (from datasets==2.9.0->inranker)\n",
      "  Using cached dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets==2.9.0->inranker) (2.2.1)\n",
      "Collecting xxhash (from datasets==2.9.0->inranker)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.9.0->inranker)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.11.1 (from fsspec[http]>=2021.11.1->datasets==2.9.0->inranker)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets==2.9.0->inranker)\n",
      "  Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.2.0 (from datasets==2.9.0->inranker)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting responses<0.19 (from datasets==2.9.0->inranker)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests==2.31.0->inranker)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests==2.31.0->inranker)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests==2.31.0->inranker)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests==2.31.0->inranker)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock (from torch==2.1.1->inranker)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions (from torch==2.1.1->inranker)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.1.1->inranker)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.1.1->inranker)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch==2.1.1->inranker)\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.27.4->inranker)\n",
      "  Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4->inranker)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-macosx_12_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.9.0->inranker)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==2.9.0->inranker)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.9.0->inranker)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.9.0->inranker)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.9.0->inranker)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.1->inranker)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.9.0->inranker)\n",
      "  Using cached multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets==2.9.0->inranker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets==2.9.0->inranker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->datasets==2.9.0->inranker) (2024.1)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.1.1->inranker)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.9.0->inranker) (1.16.0)\n",
      "Using cached inranker-1.1.0-py3-none-any.whl (13 kB)\n",
      "Using cached accelerate-0.20.1-py3-none-any.whl (227 kB)\n",
      "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "Using cached datasets-2.9.0-py3-none-any.whl (462 kB)\n",
      "Using cached protobuf-3.20.1-py2.py3-none-any.whl (162 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Using cached torch-2.1.1-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (387 kB)\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached pyarrow-15.0.0-cp311-cp311-macosx_11_0_arm64.whl (24.2 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Using cached tokenizers-0.13.3-cp311-cp311-macosx_12_0_arm64.whl (3.9 MB)\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, bitsandbytes, xxhash, urllib3, typing-extensions, tqdm, sympy, regex, pyyaml, pyarrow, protobuf, networkx, multidict, MarkupSafe, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, yarl, requests, multiprocess, jinja2, aiosignal, torch, responses, huggingface-hub, aiohttp, transformers, accelerate, datasets, inranker\n",
      "Successfully installed MarkupSafe-2.1.5 accelerate-0.20.1 aiohttp-3.9.3 aiosignal-1.3.1 attrs-23.2.0 bitsandbytes-0.41.1 certifi-2024.2.2 charset-normalizer-3.3.2 datasets-2.9.0 dill-0.3.6 filelock-3.13.1 frozenlist-1.4.1 fsspec-2024.2.0 huggingface-hub-0.21.4 idna-3.6 inranker-1.1.0 jinja2-3.1.3 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.14 networkx-3.2.1 protobuf-3.20.1 pyarrow-15.0.0 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 responses-0.18.0 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.13.3 torch-2.1.1 tqdm-4.66.1 transformers-4.27.4 typing-extensions-4.10.0 urllib3-2.2.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install inranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from inranker import T5Ranker\n",
    "\n",
    "model = T5Ranker(model_name_or_path=\"unicamp-dl/InRanker-small\")\n",
    "\n",
    "# docs = [\n",
    "#     \"condición: \",\n",
    "#     \"Learn deep learning with InRanker and transformers\"\n",
    "# ]\n",
    "# scores = model.get_scores(\n",
    "#     query=\"What is the best way to learn deep learning?\",\n",
    "#     docs=docs\n",
    "# )\n",
    "# # Scores are sorted in descending order (most relevant to least)\n",
    "# # scores -> [0, 1]\n",
    "# sorted_scores = sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "\"\"\" InRanker-small:\n",
    "sorted_scores = [\n",
    "    (0.4844, 'Learn deep learning with InRanker and transformers'),\n",
    "    (7.83e-06, 'The capital of France is Paris')\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sudoku_test = [\n",
    "  [0,5,0,0,0,0,9,0,0],\n",
    "  [0,0,0,8,3,1,2,5,0],\n",
    "  [2,0,7,0,0,0,6,1,3],\n",
    "  [9,0,6,0,0,7,0,3,0],\n",
    "  [1,2,8,0,0,0,7,0,0],\n",
    "  [0,0,0,2,0,4,0,9,6],\n",
    "  [8,1,0,7,6,0,0,2,9],\n",
    "  [7,3,4,0,2,8,0,0,1],\n",
    "  [0,0,0,4,1,0,0,0,0]]\n",
    "\n",
    "# Datos de fila: [5,9]\n",
    "# Datos faltantes: [1,2,3,4,6,7,8]\n",
    "# Intentar dato 1:\n",
    "  # Revisar cuadrante: [5,2,7]\n",
    "  # Existe el dato 1\n",
    "  # No\n",
    "    # Revisar columna: [0,0,2,9,1,0,8,7,0]\n",
    "    # Existe el dato 1:\n",
    "    # Si\n",
    "    # IMPOSIBILIDAD DETECTADA\n",
    "# Intentar dato 2:\n",
    "  # Revisar cuadrante: [5,2,7]\n",
    "  # Existe el dato 2\n",
    "  # IMPOSIBILIDAD DETECTADA\n",
    "# Intentar dato 3:\n",
    "  # Revisar cuadrante: [5,2,7]\n",
    "  # Existe el dato 3\n",
    "  # No\n",
    "    # Revisar columna: [0,0,2,9,1,0,8,7,0]\n",
    "    # Existe el dato 3:\n",
    "    # No\n",
    "      # Seleccionar dato 3 como probabilidad\n",
    "      # Revisar posibilidad otro 3 en el cuadrante: \n",
    "# P([0,0] = 3) = P([\n",
    "  # [0,5,0,0,0,0,9,0,0],\n",
    "  # [0,0,0,8,3,1,2,5,0],\n",
    "  # [2,0,7,0,0,0,6,1,3],\n",
    "  # [9,0,6,0,0,7,0,3,0],\n",
    "  # [1,2,8,0,0,0,7,0,0],\n",
    "  # [0,0,0,2,0,4,0,9,6],\n",
    "  # [8,1,0,7,6,0,0,2,9],\n",
    "  # [7,3,4,0,2,8,0,0,1],\n",
    "  # [0,0,0,4,1,0,0,0,0]]) = P([0,2]!=3) + P([0,1]!=3) + P([0,2]!=3) + P([0,3]!=3) + P([1,1]!=3) + P([0,3]!=3) + P([0,4]!=3) + P([0,1]!=4) + P([0,1]!=3) + P([0,1]!=7) + P([0,1]!=8) + P([5,0]!=3) + P([8,0]!=3)= P([0:3, 0:3] != 3|[0,0]=3) & P(X[1:-1]!=3|[0,0]=3) & P(Y[1:-1]!3|[0,0]=3) = \n",
    "# Cual es la probabilidad de que no sea 3?\n",
    "  # P([0,0]!=3) = 1 - P([0,0]=3) = 1 - Muy baja\n",
    "\n",
    "Acciones\n",
    "- Anotar datos faltantes\n",
    "- Escribir dato faltante\n",
    "\n",
    "- Revisar cuadrante / obtener datos de cuadrante\n",
    "- Revisar fila / obtener datos de fila\n",
    "- Revisar columna / obtener datos de columna\n",
    "\n",
    "- Tomar decisión\n",
    "  - INICIO: Suponiendo que empezamos desde [0,0]\n",
    "  - Anotar datos faltantes en la posición faltante en el cuadrante de [0,0]\n",
    "    - Seleccionar cuadrante de la selección\n",
    "    - Tomar siguiente posición faltante en cuadrante\n",
    "    - Revisar posibilidad de datos faltantes en cuadrante, fila y columna\n",
    "      - Revisar posibilidad de datos faltantes en cuadrante\n",
    "        - Obtener datos de cuadrante\n",
    "        - Validar datos de cuadrante\n",
    "      - Revisar posibilidad de datos faltantes en fila\n",
    "        - Obtener datos de fila\n",
    "        - Validar datos de fila\n",
    "      - Revisar posibilidad de datos faltantes en columna\n",
    "        - Obtener datos de columna\n",
    "        - Validar datos de columna\n",
    "  - Anotar datos faltantes en la siguiente posición faltante en la fila\n",
    "    - Seleccionar fila de la selección\n",
    "    - Tomar siguiente posición faltante en fila\n",
    "    - Revisar posibilidad de datos faltantes en cuadrante, fila y columna\n",
    "  - Anotar datos faltantes en la siguiente posición faltante en la columna\n",
    "    - Seleccionar columna de la selección\n",
    "    - Tomar siguiente posición faltante en columna\n",
    "    - Revisar posibilidad de datos faltantes en cuadrante, fila y columna\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- https://blog.thedojo.mx/2023/02/08/maquinas-de-turing-no-deterministas-y-problemas-np.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
